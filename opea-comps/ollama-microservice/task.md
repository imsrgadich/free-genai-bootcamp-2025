# OPEA Comps

## Difficulty: Level 200

## Business Goal:
The company wants you to explore the effort it would take to run the AI workloads completely on servers that will live in-house. The fractional CTO, suggests that its best practice to run workloads in containers or kubenetes. You as the AI Engineer have been tasked to determine how to learn to work with the building blocks to constructor your own GenAI workloads running on containers.


## Technical Uncertainty
- How do we deploy this service?
- How do I expose it in the company networks?
- Do I need kubernetes to orchestrate two services together?

## Technical Restrictions
- GenAIComps ([GitHub Repo](https://github.com/opea-project/GenAIComps))
- [OPEA Comps Project](https://opea-project.github.io/latest/GenAIComps/README.html)
- Docker Containers

## Homework Challenges
- Implement and deploy Ollama server in docker container
- Orchestrate multiple services eg. 2 or 3 together or Try and get a different comp working that Andrew did use not use.
- Homework Bonuses: Make a tutorial or technical doc that is public on LinkedIn, Medium, Hashnode, Your Blog. Tag Andrew or show off the work in the Discord show-and-tell.
